{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "YNPAqXna_kwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18d4385-0ddd-40a8-a9ef-bdda2ddcbd56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gnElb6H0_Xj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2dd804-917a-46ed-dedf-8f75e0ceef7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "#import wordnet\n",
        "nltk.download( 'punkt_tab' )\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download( 'averaged_perceptron_tagger_eng' )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=input ()"
      ],
      "metadata": {
        "id": "iDJQ6OJFMZRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5fce40-f4be-4808-c083-5b80fadfafa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The only way to do great work is to love what you do\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the parts of speech\n",
        "for word, tag in pos_tags:\n",
        "    print(word, tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRqZaAF6ARrL",
        "outputId": "ddfe9858-e42e-481e-e833-c8d7bab47f0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DT\n",
            "only JJ\n",
            "way NN\n",
            "to TO\n",
            "do VB\n",
            "great JJ\n",
            "work NN\n",
            "is VBZ\n",
            "to TO\n",
            "love VB\n",
            "what WP\n",
            "you PRP\n",
            "do VBP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the sentence into words\n",
        "words = word_tokenize(sentence)\n",
        "# Identify the parts of speech for each word\n",
        "pos_tags= nltk.pos_tag(words)"
      ],
      "metadata": {
        "id": "4DM8gOaiAHQx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Identify synonyms and antonyms for each word\n",
        "synonyms =[]\n",
        "antonyms =[]\n",
        "for word in words:\n",
        "\tfor syn in wordnet.synsets(word) :\n",
        "\t\tfor lemma in syn.lemmas():\n",
        "\t\t\tsynonyms . append (lemma . name( ) )\n",
        "\t\t\tif lemma . antonyms():\n",
        "\t\t\t\tantonyms . append ( lemma. antonyms ( ) [0] . name ( ) )\n",
        "# Print the synonyms and antonyms\n",
        "print ( \"Synonyms : \" ,set (synonyms) )\n",
        "print ( \"Antonyms : \" ,set(antonyms) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEavtnMUAToR",
        "outputId": "04ab558d-c999-46c8-ae69-715c64d31aae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms :  {'know', 'dearest', 'enjoy', 'love', 'way_of_life', 'be', 'get_along', 'have_intercourse', 'only_if', 'bonk', 'roll_in_the_hay', 'erotic_love', 'sexual_love', 'workplace', 'room', 'make_up', 'DO', 'bang-up', 'cost', 'swell', 'direction', 'dandy', 'heavy', 'making_love', 'slap-up', 'mode', 'lonesome', 'peachy', 'keen', 'execute', 'expectant', 'bring', 'do_work', 'puzzle_out', 'majuscule', 'cultivate', 'solve', 'answer', 'smashing', 'lone', 'way', 'work', 'brawl', 'gravid', 'ferment', 'get_laid', 'exercise', 'outstanding', 'follow', 'lick', 'sleep_with', 'lie_with', 'alone', 'bed', 'operate', 'live', 'love_life', 'enceinte', 'just', 'mold', 'represent', 'but', 'coif', 'play', 'great', 'screw', 'big', 'solitary', 'groovy', 'agency', 'sole', 'run', 'equal', 'work_on', 'have_it_away', 'Doctor_of_Osteopathy', 'cause', 'act', 'put_to_work', 'hump', 'have_a_go_at_it', 'embody', 'do_it', 'practise', 'study', 'capital', 'fare', 'personify', 'bully', 'have_sex', 'piece_of_work', 'entirely', 'knead', 'arrange', 'do', 'sour', 'lovemaking', 'form', 'exploit', 'make', 'jazz', 'get_it_on', 'simply', 'forge', 'behave', 'beloved', 'bash', 'influence', 'large', 'function', 'merely', 'cracking', 'suffice', 'elbow_room', 'only', 'fashion', 'go', 'coiffe', 'means', 'make_love', 'honey', 'doh', 'work_out', 'sleep_together', 'right_smart', 'turn', 'wreak', 'eff', 'set', 'comprise', 'mould', 'exclusively', 'only_when', 'ut', 'constitute', 'with_child', 'practice', 'nifty', 'shape', 'coiffure', 'body_of_work', 'passion', 'have_it_off', 'fuck', 'solely', 'bang', 'make_out', 'figure_out', 'perform', 'path', 'employment', 'manage', 'crop', 'be_intimate', 'style', 'manner', 'not_bad', 'exist', 'process', 'oeuvre', 'act_upon', 'corking', 'dress', 'neat', 'make_for', 'serve', 'come', 'dear'}\n",
            "Antonyms :  {'differ', 'malfunction', 'unmake', 'idle', 'hate'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kd_97SRFAgaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8bX8Og3WAbBg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}